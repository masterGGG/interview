# 5种IO模型
IO分为两个阶段（一旦拿到数据就是数据处理阶段了，不再是IO阶段）：
1. 数据准备阶段
2. 数据拷贝阶段，（将网卡数据从内核空间复制到用户空间缓冲区）
阻塞非阻塞的区别在于第一阶段发起的IO请求是否会被阻塞。如果一直阻塞到数据准备完毕，那就是传统的阻塞型IO。一般来讲`阻塞IO`、`非阻塞IO`、`IO多路复用`以及`信号驱动IO`都属于同步IO模型。
同步异步模型的区别在于第二步是否阻塞。
## 阻塞IO
调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的去检查这个函数有没有返回，必须等这个函数返回才能进行下一步动作
## 非阻塞IO
非阻塞等待，每隔一段时间就去检测IO事件是否就绪。没有就绪就可以做其他事。
## 信号驱动IO
信号驱动IO:linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO时间就绪，进程收到SIGIO信号。然后处理IO事件。
## IO复用/多路转接IO
linux用select/poll函数实现IO复用模型，这两个函数也会使进程阻塞，但是和阻塞IO所不同的是这两个函数可以同时阻塞多个IO操作。而且可以同时对多个读操作、写操作的IO函数进行检测。知道有数据可读或可写时，才真正调用IO操作函数
## 异步IO
linux中，可以调用aio_read函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。

# select与epoll的区别
> 1. select结构中的描述符标识位只有1024位，所以select能监听的FD数量有限，对于那些需要支持的上万连接数目的IM服务器来说显然太少了。epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目。

> 2. 无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，select和poll每次调用都需要将FD集合在用户空间和内核空间来回拷贝，epoll是通过内核与用户空间mmap同一块内存实现的FD共享。

> 3. epoll的IO效率不随FD数目增加而线性下降。传统的select/poll另一个致命弱点就是当你拥有一个很大的socket集合，不过由于网络延时，任一时间只有部分的socket是"活跃"的，但是select/poll每次调用都会线性扫描全部的集合，导致效率呈现线性下降。但是epoll不存在这个问题，它只会对"活跃"的socket进行操作---这是因为在内核实现中epoll维护一个就绪链表，每次调用需要扫描就绪链表即可。

# epoll工作模式
> 1. LT模式：Level Triggered水平触发  
这个是缺省的工作模式。同时支持block socket和non-block socket。内核会告诉程序员一个文件描述符是否就绪了。如果程序员不作任何操作，内核仍会通知。
LT适用于高吞吐的服务、IO多路复用
> 2. ET模式：Edge Triggered 边缘触发  
是一种高速模式。仅当状态发生变化的时候才获得通知。这种模式假定程序员在收到一次通知后能够完整地处理事件，于是内核不再通知这一事件。
ET适用于实时性要求高的服务。
# keepalive
链接建立之后，如果应用层或者上层协议一直不发送数据，或者是相隔很长时间才发送一次数据，当链接很久没有数据报文传输时如何去确定对方在线，到底是掉线，还是确实没有数据传输，链接还需不需要保持，这种情况在tcp协议设计中是需要考虑的。
tcp协议通过自动发送数据为空的探测报文给对方，如果对方回应，说明在线，链接可以继续保持，如果对方没有报文返回，并且重试多次之后，则认为链接丢失，没有必要保持链接，释放资源。
```
//开启keepalive
SO_KEEPALIVE
//设置每多少秒发送一次心跳包
TCP_KEEPIDLE   
//对端没有回应心跳包后，每隔多少秒发送一次心跳包  
TCP_KEEPINTVL 
//关闭一个非活跃链接之前的最大重试次数
TCP_KEEPCNT
```

# TCP_NODELAY
打开TCP_NODELAY:禁用nagle算法
    增加通信的延时，增加带宽利用率。比较适合在容忍高延迟、数据量大的通信场景。
禁用TCP_NODELAY
    会增加小包的数量，但是可以提高响应速度。适合在低延迟、低带宽的系统场景。