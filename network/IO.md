# 5种IO模型
IO分为两个阶段（一旦拿到数据就是数据处理阶段了，不再是IO阶段）：
1. **数据准备**阶段
2. **数据拷贝**阶段，（将网卡数据从内核空间复制到用户空间缓冲区）
阻塞非阻塞的区别在于第一阶段发起的IO请求是否会被阻塞。如果一直阻塞到数据准备完毕，那就是传统的阻塞型IO。
同步异步模型的区别在于第二步是否阻塞。一般来讲`阻塞IO`、`非阻塞IO`、`IO多路复用`以及`信号驱动IO`都属于同步IO模型。
## 阻塞IO
调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的去检查这个函数有没有返回，必须等这个函数返回才能进行下一步动作
## 非阻塞IO
非阻塞等待，每隔一段时间就去检测IO事件是否就绪。没有就绪就可以做其他事。
## 信号驱动IO
信号驱动IO:linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO时间就绪，进程收到SIGIO信号。然后处理IO事件。
## IO复用/多路转接IO
linux用select/poll函数实现IO复用模型，这两个函数也会使进程阻塞，但是和阻塞IO所不同的是这两个函数可以同时阻塞多个IO操作。而且可以同时对多个读写操作的IO函数进行检测。直到有数据可读或可写时，才真正调用IO操作函数
## 异步IO
linux中，可以调用aio_read函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。

# select与epoll的区别
> 1. select结构中的描述符标识位只有1024位，所以select能监听的FD数量有限，对于那些需要支持的上万连接数目的IM服务器来说显然太少了。epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目。

> 2. 无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，select和poll每次调用都需要将FD集合在用户空间和内核空间来回拷贝，epoll是通过内核与用户空间mmap同一块内存实现的FD共享。

> 3. epoll的IO效率不随FD数目增加而线性下降。传统的select/poll另一个致命弱点就是当你拥有一个很大的socket集合，不过由于网络延时，任一时间只有部分的socket是"活跃"的，但是select/poll每次调用都会线性扫描全部的集合，导致效率呈现线性下降。但是epoll不存在这个问题，它只会对就绪的socket进行操作---这是因为在内核实现中epoll维护一个就绪链表，每次调用需要扫描就绪链表即可。

# epoll工作模式
> 1. LT模式：Level Triggered水平触发  
这个是缺省的工作模式。同时支持block socket和non-block socket。内核会告诉程序员一个文件描述符是否就绪了。如果程序员不作任何操作，内核仍会通知。
LT适用于高吞吐的服务、IO多路复用
> 2. ET模式：Edge Triggered 边缘触发  
是一种高速模式。仅当状态发生变化的时候才获得通知。这种模式假定程序员在收到一次通知后能够完整地处理事件，于是内核不再通知这一事件。
ET适用于实时性要求高的服务。

# Reactor模型
Reactor模型用于同步I/O，而Proactor模型运用于异步I/O操作。
Reactor模型基于事件驱动，特别适合处理海量的I/O事件。
Reactor模型中定义的三种角色：
Reactor：负责将I/O事件分派给对应的Handler。新的事件包含连接建立就绪、读就绪、写就绪等。
Acceptor：处理客户端新连接，并分派请求到处理器链中。
Handler：将自身与事件绑定，执行非阻塞读/写任务，完成channel的读入，完成处理业务逻辑后，负责将结果写出channel。可用资源池来管理。
# 定时器，时间轮算法
堆定时器
epoll定时器
时间轮定时器 
